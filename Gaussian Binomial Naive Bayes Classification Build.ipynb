{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Purpose of this Model is to build a classifier that can do the following:\n",
    "\n",
    "#### Predict if a post is from a driver or a rider. Build a Gausian Binomial Naive Bayes Model given post content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Copyright Product of HitchHiqe Â© 2019\n",
    ">\n",
    ">  Author: Qasim Wani.\n",
    ">\n",
    "> Written: 26th November, 2019\n",
    ">\n",
    "> Version: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import sklearn.model_selection as skl\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Data Extraction and Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/qasim/Desktop/Exigence/HitchHiqe - official/sourcecode/hitchHiqe/Fraper/data/dev train/raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Type != -1] ## Dropping irrelevant data\n",
    "X = np.array(df.iloc[:,1])\n",
    "y = np.array(df.iloc[:,-1])\n",
    "X_train, X_test, y_train, y_test = skl.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MongoDB Object ID</th>\n",
       "      <th>Post</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>client id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Post Link</th>\n",
       "      <th>Post Timestamp</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5dddf40c7d7e3e467c07a921</td>\n",
       "      <td>leaving sunday december 1st (can make stops on...</td>\n",
       "      <td>11/26/19, 9:49 PM</td>\n",
       "      <td>https://www.facebook.com/eric.aponte.5817</td>\n",
       "      <td>Eric Aponte</td>\n",
       "      <td>https://www.facebook.com/groups/19322097409271...</td>\n",
       "      <td>1574822985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5dddf40c7d7e3e467c07a91e</td>\n",
       "      <td>please let me know if anyone is driving to ral...</td>\n",
       "      <td>11/26/19, 9:08 PM</td>\n",
       "      <td>https://www.facebook.com/yogen.phanse</td>\n",
       "      <td>Yogen Phanse</td>\n",
       "      <td>https://www.facebook.com/groups/19322097409271...</td>\n",
       "      <td>1574820503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5dddf40c7d7e3e467c07a922</td>\n",
       "      <td>driving from asheville, nc to vt on saturday, ...</td>\n",
       "      <td>11/26/19, 4:23 PM</td>\n",
       "      <td>https://www.facebook.com/haley.fontaine.3</td>\n",
       "      <td>Haley Fontaine</td>\n",
       "      <td>https://www.facebook.com/groups/19322097409271...</td>\n",
       "      <td>1574803421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MongoDB Object ID  \\\n",
       "0  5dddf40c7d7e3e467c07a921   \n",
       "1  5dddf40c7d7e3e467c07a91e   \n",
       "2  5dddf40c7d7e3e467c07a922   \n",
       "\n",
       "                                                Post          Post Date  \\\n",
       "0  leaving sunday december 1st (can make stops on...  11/26/19, 9:49 PM   \n",
       "1  please let me know if anyone is driving to ral...  11/26/19, 9:08 PM   \n",
       "2  driving from asheville, nc to vt on saturday, ...  11/26/19, 4:23 PM   \n",
       "\n",
       "                                   client id            Name  \\\n",
       "0  https://www.facebook.com/eric.aponte.5817     Eric Aponte   \n",
       "1      https://www.facebook.com/yogen.phanse    Yogen Phanse   \n",
       "2  https://www.facebook.com/haley.fontaine.3  Haley Fontaine   \n",
       "\n",
       "                                           Post Link  Post Timestamp  Type  \n",
       "0  https://www.facebook.com/groups/19322097409271...      1574822985     0  \n",
       "1  https://www.facebook.com/groups/19322097409271...      1574820503     1  \n",
       "2  https://www.facebook.com/groups/19322097409271...      1574803421     0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to see for null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null objects in our set:\n",
      " MongoDB Object ID    0\n",
      "Post                 0\n",
      "Post Date            0\n",
      "client id            0\n",
      "Name                 0\n",
      "Post Link            0\n",
      "Post Timestamp       0\n",
      "Type                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull objects in our set:\\n\",df.notnull().count() - df.isnull().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looks good! Let's proceed to building the actual model now and more data synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Data Synthesis and Document Matrix Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "> Type = 0 : <strong>Driver</strong>\n",
    ">\n",
    "> Type = 1 : <strong>Rider</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, y):\n",
    "    \"\"\"\n",
    "    This function accepts two parameters.\n",
    "    1. X: Posts.\n",
    "    2. y : Type of posts (0 = Driver ; 1 = Rider)\n",
    "    It returns two np.array() objects:\n",
    "    1. driver: An np.array() of all driver posts\n",
    "    2. rider: An np.array() of all rider posts\n",
    "    \"\"\"\n",
    "    driver = []     # driver = 0\n",
    "    rider = [] # rider = 1\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        one_post = str(X[i]).lower().strip()\n",
    "        one_post = re.sub(r'[^a-zA-Z0-9\\s]', \"\", one_post)\n",
    "        if(y[i] == 1):\n",
    "            rider.append(one_post)\n",
    "        else:\n",
    "            driver.append(one_post)\n",
    "    return np.array(driver), np.array(rider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Driver Posts : 129\n",
      "Number of Training Rider Posts : 53\n"
     ]
    }
   ],
   "source": [
    "driver_train, rider_train = classify(X_train, y_train)\n",
    "print(\"Number of Training Driver Posts : {0}\\nNumber of Training Rider Posts : {1}\"\n",
    "      .format(len(driver_train), len(rider_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wow. This is some nice data! A quite even proportion of drivers to riders. Exciting for HitchHiqe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, in order to detect which post is from a driver or a rider, we need to tokenize words. \n",
    "This will help identify the N most occurring words in two types of posts.\n",
    "The model shall be dependent on 1-4 most occurring words using ngram and bag of word approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_tokenizer(data, n=1, topN=314):\n",
    "    \"\"\"\n",
    "    This function finds the n most occurring words in our data.\n",
    "    Returns a list of sorted tuples of topN most occurring words.\n",
    "    \n",
    "    Parameters: \n",
    "    1. n    : Int. Number of words to tokenize. By default, n = 1.\n",
    "    2. data : np.array() object. List of datapoints to tokenize.\n",
    "    3. topN : Int. Top N batches to return. By default, topN = 314\n",
    "    \"\"\"\n",
    "    n_word_count = {}\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for i in range(len(data)):\n",
    "        n_grams = ngrams(word_tokenize(data[i]), n)\n",
    "#         tokenized = [word for word in n_grams if word not in stop_words] <-- Use this when ignoring stop_words\n",
    "        tokenized = [ ' '.join(grams) for grams in n_grams]\n",
    "        for tokens in tokenized:\n",
    "#             if(tokens not in stop_words): <-- Use this when ignoring stop_words\n",
    "            if(tokens not in n_word_count):\n",
    "                n_word_count[tokens] = 1\n",
    "            else:\n",
    "                n_word_count[tokens] += 1\n",
    "            \n",
    "    most_common = np.array(Counter.most_common(n_word_count))[:topN]\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf_idf(words, size):\n",
    "    \"\"\"Calculates the term frequency of top-N-most common words in all Posts.\n",
    "        \n",
    "        Returns a new list with the word, frequency, and occurrence as a fraction\n",
    "        \n",
    "        Takes in two parameters: \n",
    "        1. words : a list of tuples consisting of most frequent words and their respective frequencies\n",
    "        2. size  : number of tweets in given class\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    new_list = []\n",
    "    for i in range(len(words)):\n",
    "        num = float(words[i][-1])\n",
    "        x = float(num/size)\n",
    "        a = list(words[i])\n",
    "        y = float(x)\n",
    "        y = x*float(np.log(1/y))\n",
    "        a.append(y)\n",
    "        new_list.append(a)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n_tf_idf(n_start, n_end, driver_data_train, rider_data_train):\n",
    "    \"\"\"\n",
    "    Calculates the term frequency - inverse document frequency of the\n",
    "    n most frequent words\n",
    "    \n",
    "    Parameters : \n",
    "    1. n_start : number to start from (n_start is inclusive)\n",
    "    2. n_end   : number to end (n_end is exclusive)\n",
    "    3. driver_data_train : Driver Training data\n",
    "    4. rider_data_train : Rider Training data\n",
    "    \n",
    "    Returns :\n",
    "    1. driver_all_TDM : List of Driver TDM of n most frequent words.\n",
    "    2. rider_all_TDM  : List of Rider TDM of n most frequent words.\n",
    "    \"\"\"\n",
    "    rider_all_TDM = []\n",
    "    driver_all_TDM = []\n",
    "    for i in range(n_start, n_end):\n",
    "        \n",
    "        n_sorted_driver = ngram_tokenizer(driver_train, i)\n",
    "        n_sorted_rider = ngram_tokenizer(rider_train, i)   \n",
    "        \n",
    "        driver_TD_IDF = calc_tf_idf(n_sorted_driver, len(driver_data_train))\n",
    "        rider_TD_IDF = calc_tf_idf(n_sorted_rider, len(rider_data_train))\n",
    "        \n",
    "        driver_all_TDM.append(driver_TD_IDF)\n",
    "        rider_all_TDM.append(rider_TD_IDF)\n",
    "        \n",
    "    return np.array(driver_all_TDM), np.array(rider_all_TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's calculate the TD-IDF for the first 100 most common tokenized words (1 - 4 words)\n",
    "driver_TDM, rider_TDM = first_n_tf_idf(1, 5, driver_train, rider_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's represent it into a pandas dataframe\n",
    "\n",
    "driver_df_TDM = pd.DataFrame(data=driver_TDM[0], columns=['Terms','Frequency','TF-IDF'])\n",
    "rider_df_TDM = pd.DataFrame(data=rider_TDM[0], columns=['Terms','Frequency','TF-IDF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's sort the dataframe objects based on descending frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ride</td>\n",
       "      <td>47</td>\n",
       "      <td>0.36786236995833976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>at</td>\n",
       "      <td>47</td>\n",
       "      <td>0.36786236995833976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>you</td>\n",
       "      <td>44</td>\n",
       "      <td>0.3668790844923262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>message</td>\n",
       "      <td>43</td>\n",
       "      <td>0.3662040962227032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3653488140720059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>54</td>\n",
       "      <td>0.3645328009384456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>around</td>\n",
       "      <td>41</td>\n",
       "      <td>0.36430894452675916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>driving</td>\n",
       "      <td>55</td>\n",
       "      <td>0.3634601321868688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>off</td>\n",
       "      <td>40</td>\n",
       "      <td>0.3630799845729414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>me</td>\n",
       "      <td>57</td>\n",
       "      <td>0.3608944556747748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>and</td>\n",
       "      <td>38</td>\n",
       "      <td>0.3600356379545805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Terms Frequency               TF-IDF\n",
       "9      ride        47  0.36786236995833976\n",
       "10       at        47  0.36786236995833976\n",
       "11      you        44   0.3668790844923262\n",
       "12  message        43   0.3662040962227032\n",
       "13        i        42   0.3653488140720059\n",
       "8       for        54   0.3645328009384456\n",
       "14   around        41  0.36430894452675916\n",
       "7   driving        55   0.3634601321868688\n",
       "15      off        40   0.3630799845729414\n",
       "6        me        57   0.3608944556747748\n",
       "16      and        38   0.3600356379545805"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Driver TDM, sorted\n",
    "driver_df_TDM.sort_values(by=\"TF-IDF\",ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>will</td>\n",
       "      <td>20</td>\n",
       "      <td>0.367758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vt</td>\n",
       "      <td>18</td>\n",
       "      <td>0.366765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gas</td>\n",
       "      <td>23</td>\n",
       "      <td>0.362271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friday</td>\n",
       "      <td>16</td>\n",
       "      <td>0.361571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the</td>\n",
       "      <td>16</td>\n",
       "      <td>0.361571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>or</td>\n",
       "      <td>24</td>\n",
       "      <td>0.358749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pay</td>\n",
       "      <td>25</td>\n",
       "      <td>0.354442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sunday</td>\n",
       "      <td>13</td>\n",
       "      <td>0.344707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>if</td>\n",
       "      <td>12</td>\n",
       "      <td>0.336314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "      <td>29</td>\n",
       "      <td>0.329941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>me</td>\n",
       "      <td>11</td>\n",
       "      <td>0.326346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Terms Frequency    TF-IDF\n",
       "10    will        20  0.367758\n",
       "11      vt        18  0.366765\n",
       "9      gas        23  0.362271\n",
       "12  friday        16  0.361571\n",
       "13     the        16  0.361571\n",
       "8       or        24  0.358749\n",
       "7      pay        25  0.354442\n",
       "14  sunday        13  0.344707\n",
       "15      if        12  0.336314\n",
       "6     from        29  0.329941\n",
       "18      me        11  0.326346"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rider TDM, sorted\n",
    "rider_df_TDM.sort_values(by=\"TF-IDF\",ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Gaussian Binomial Naive Bayes Algorithm Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior(likelihood, prior, marginal):\n",
    "    \"\"\"\n",
    "    Calculates the posterior probability of a Post Type being a driver/rider.\n",
    "    Return the posterior value (0 - 1) {Spectrum}\n",
    "    Parameters:\n",
    "    1. likelihood : The likelihood probability (float : 0 - 1)\n",
    "    2. prior : The prior probability (float : 0 - 1)\n",
    "    3. marginal : The marginal probability (float : 0 - 1)\n",
    "    \"\"\"\n",
    "    num = float(likelihood * prior)\n",
    "    marginal = num/float(marginal)\n",
    "    return float(marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_marginal(word, _type, driver_tdm, rider_tdm):\n",
    "    \"\"\"\n",
    "    Calculates the marginal probability of a word.\n",
    "    Returns the marginal probability (0-1) as a float.\n",
    "    Parameters:\n",
    "    1. word : the word to calculate marginal probability for.\n",
    "    2. _type : Indicates the _type of post, generated from one_naive_bayes() : 0 -> DRIVER; 1 -> RIDER\n",
    "    3. driver_tdm : The associated Driver TDM\n",
    "    4. rider_tdm  : The associated Rider TDM\n",
    "    \"\"\"\n",
    "    marginal_DRIVER = 1    \n",
    "    marginal_RIDER = 1\n",
    "    \n",
    "    for driver, rider in zip(driver_tdm, rider_tdm):\n",
    "        if(driver[0] == word):\n",
    "            marginal_DRIVER = float(driver[1])\n",
    "        if(rider[0] == word):\n",
    "            marginal_RIDER = float(rider[1])\n",
    "    \n",
    "    frequency = marginal_RIDER + marginal_DRIVER\n",
    "    marginal_DRIVER /= frequency\n",
    "    marginal_RIDER /= frequency\n",
    "    \n",
    "    if(_type == 0):\n",
    "        return float(marginal_DRIVER)\n",
    "    elif(_type == 1):\n",
    "        return float(marginal_RIDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_naive_bayes(pst, rider_T_D_M, driver_T_D_M):\n",
    "    \"\"\"\n",
    "    Predicts if a Post is regarding a Rider request (RIDER --> 1) or Ride Offer (DRIVER --> 0).\n",
    "    \n",
    "    Returns 1 if Rider; \n",
    "    Returns 0 if Driver;\n",
    "    \n",
    "    Also Returns the posterior probability of Driver and Rider Posts.\n",
    "    \n",
    "    Parameters:\n",
    "    1. pst : Post to calculate the posterior for; Type : np.array() [Split each word.]\n",
    "    2. rider_tdm : The Rider based TDM.\n",
    "    3. driver_tdm : The Driver based TDM.\n",
    "    \"\"\"\n",
    "    \n",
    "    tots_driver = 0\n",
    "    tots_rider = 0\n",
    "    size = 0\n",
    "    i = 0\n",
    "    for (driver_tdm, rider_tdm) in zip(driver_T_D_M, rider_T_D_M):\n",
    "        i += 1\n",
    "        fb_POST = list(ngrams(word_tokenize(pst), i))\n",
    "    # Calculating the prior probability of Driver and Rider Post\n",
    "        size_driver_tdm = len(driver_tdm)\n",
    "        size_rider_tdm = len(rider_tdm)\n",
    "        total_size = size_driver_tdm + size_rider_tdm\n",
    "        prior_DRIVER = float(size_driver_tdm / total_size)\n",
    "        prior_RIDER = float(size_rider_tdm / total_size)\n",
    "    #-----------------------------------------------------------\n",
    "        likelihood_DRIVER = 1\n",
    "        likelihood_RIDER = 1\n",
    "\n",
    "        marginal_DRIVER = 1\n",
    "        marginal_RIDER = 1\n",
    "\n",
    "        for word in fb_POST:\n",
    "            word = \" \".join(word)\n",
    "            for (checker_DRIVER, checker_RIDER) in zip(driver_tdm, rider_tdm):\n",
    "                if(checker_DRIVER[0] == word):\n",
    "                    likelihood_DRIVER *= float(checker_DRIVER[-1])\n",
    "                    marginal_DRIVER *= calculate_marginal(word, 0, driver_tdm, rider_tdm)\n",
    "                    \n",
    "                if(checker_RIDER[0] == word):\n",
    "                    likelihood_RIDER *= float(checker_RIDER[-1])\n",
    "                    marginal_RIDER *= calculate_marginal(word, 1, driver_tdm, rider_tdm)\n",
    "\n",
    "        posterior_DRIVER = calculate_posterior(likelihood_DRIVER, prior_DRIVER, marginal_DRIVER)\n",
    "        posterior_RIDER = calculate_posterior(likelihood_RIDER, prior_RIDER, marginal_RIDER)\n",
    "        tots_driver += abs(posterior_DRIVER)\n",
    "        tots_rider += abs(posterior_RIDER)\n",
    "        size += 1\n",
    "        \n",
    "    DRIVER_prob = float(tots_driver / size)\n",
    "    RIDER_prob = float(tots_rider / size)\n",
    "    \n",
    "    if(DRIVER_prob > RIDER_prob):\n",
    "        return DRIVER_prob, RIDER_prob, 1\n",
    "    return DRIVER_prob, RIDER_prob, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Validation\n",
    "#### (no k-cross and hyper-parameter validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polish_text(text):\n",
    "    \"\"\"\n",
    "    Polished text by making it lowercase and removing punctuation.\n",
    "    Returns the polished rext.\n",
    "    Parameters:\n",
    "    1. text : text to polish\n",
    "    \"\"\"\n",
    "    sentence = str(text).lower().strip()\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9\\s]', \" \", sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data, rider_tdm, driver_tdm):\n",
    "    \"\"\"\n",
    "    This function validates our GBN-NB Model.\n",
    "    Returns the number of estimated Driver and Rider tweets\n",
    "    Parameters:\n",
    "    1. data : dataset of Posts to classify. Type = np.array()\n",
    "    \"\"\"\n",
    "    DRIVER = 0\n",
    "    RIDER = 0\n",
    "    for i in range(len(data)):\n",
    "        post = polish_text(data[i])\n",
    "        _, _, result = one_naive_bayes(post, rider_tdm, driver_tdm)\n",
    "        if(result == 1):\n",
    "            RIDER += 1\n",
    "        else:\n",
    "            DRIVER += 1\n",
    "            \n",
    "    return DRIVER, RIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let the validation begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the number of trained Driver and Rider Posts as calculated from the GBN-NB Model\n",
    "driver_post_trained, rider_post_trained = validation(X_train, rider_TDM, driver_TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 55 <-- Model Generated ||| Actual --> 129 53\n"
     ]
    }
   ],
   "source": [
    "print(driver_post_trained, rider_post_trained, \"<-- Model Generated ||| Actual -->\", len(driver_train), len(rider_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision score : 98.4%\n"
     ]
    }
   ],
   "source": [
    "precision_score_Train = (driver_post_trained/len(driver_train))*100\n",
    "print(\"Training Precision score : {0:.3g}%\".format(precision_score_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Holy Fuck!!! The Gaussian Binomial Naive Bayes Model correctly detected 98.4% of posts.\n",
    "## Let's now try to see how our model behaves with testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the number of test Driver and Rider Posts\n",
    "driver_post_test, rider_post_test = validation(X_test, rider_TDM, driver_TDM)\n",
    "validated_driver_test, validated_rider_test = classify(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 26 <-- Model Prediction vs. Actual --> 63 27\n"
     ]
    }
   ],
   "source": [
    "print(driver_post_test, rider_post_test, \"<-- Model Prediction vs. Actual -->\", len(validated_driver_test), len(validated_rider_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Precision score : 96.3%\n"
     ]
    }
   ],
   "source": [
    "precision_score_Test = (rider_post_test/len(validated_rider_test))*100\n",
    "print(\"Testing Set Precision score : {0:.3g}%\".format(precision_score_Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: \n",
    "### Training Set Precision score : 98.4%\n",
    "### Testing Set Precision score : 96.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "### That's sexy good. 96.3% Test validation score in detecting a driver or rider post.\n",
    "### Implementing this into HitchHiqe is literally going to take the product through the roof. \n",
    "### Now, the challenging part: Unleashing the engineering onto the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For further testing purposes, let me run the bayes net through totally different text from NOVA carpool FB group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_nova_carpool_group_sample_post = \"Leaving Leesburg area Sunday around 10/11 am. Message me if you need a ride back to school.\"\n",
    "driver_posterior, rider_posterior, result = one_naive_bayes(vt_nova_carpool_group_sample_post, rider_TDM, driver_TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.923161879676172, 0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rider_posterior / driver_posterior, result # 0 --> Driver ; 1 --> Rider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wow. A totally random post from a completely new source ranks this post as a driver related by a factor of ~24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try another, a bit more confusing post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusing_post = \"Anyone driving to DC on Thursday 11/28? Need a ride.\"\n",
    "driver_posterior2, rider_posterior2, result2 = one_naive_bayes(confusing_post, rider_TDM, driver_TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2871249275197578, 0.3203524308752435, 0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_posterior2, rider_posterior2, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Okay, this is indeed a bit confusing, hence why the algorithm incorrectly classified it. \n",
    "### But the striking closeness in results is remarkable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_post = \"Need a ride back to tech from Springfield area on Sunday 12/1 will pay gas\"\n",
    "dr3, rd3, rs3 = one_naive_bayes(third_post, rider_TDM, driver_TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.069096214230044, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr3 / rd3, rs3 # 0 --> Driver ; 1 --> Rider\n",
    "## Nice!!! (Nearly 10 times as likely to be a post from a rider than a driver.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the following post works, I'll be celebrating by leaving my dorm to stretch for a minute after 4 straight days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_test = \"Yoo so this is my third time posting. Is no one leaving on Saturday? Looking for a ride! Will pay for gas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9777276010766784, 1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr4, rd4, rs4 = one_naive_bayes(last_test, rider_TDM, driver_TDM)\n",
    "dr4 / rd4, rs4 # 0 --> Driver ; 1 --> Rider\n",
    "## Nice!!! (Nearly 2 times as likely to be a post from a rider than a driver.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuck. Guess I have to leave now... Now, I somehow need to figure out how to implement this on HitchHiqe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
